# -*- coding: utf-8 -*-
"""HW3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hoxKZjCPMaw_4MqeOQ1JoL-BRcfGjVXF
"""

# Copyright 2020 Forrest Sheng Bao
# GNU GPL v3.0 or later
# Author : Yu-Pin Liang (Jasmine)

import operator
import numpy
import sklearn, sklearn.tree

def estimate_gini_impurity(feature_values, threshold, labels, polarity): 
    determine_array = []
    for i in range (len(feature_values)):
      polarity (feature_values[i],threshold)
      determine_array.append(polarity (feature_values[i],threshold))
    
    determine_array =numpy.array(determine_array)
    label_true = []

    for i in range (len(determine_array)):
      if determine_array[i] == True:
        label_true.append(labels[i])
    
    label_true =numpy.array(label_true)
    count_true = 0
    for i in range (len(label_true)):
      if label_true[i] == 1:
        count_true = count_true+1

    count_false = len(label_true) - count_true

    if len(label_true) == 0:
      gini_impurity = 0.5
    else :
      gini_impurity = 1-(count_true/len(label_true))**2-(count_false/len(label_true))**2

    return gini_impurity

def estimate_gini_impurity_expectation(feature_values, threshold, labels):
    true_positive = numpy.array(numpy.logical_and( numpy.array(feature_values) > threshold, numpy.array(labels) == 1))
    true_negative = numpy.array(numpy.logical_and( numpy.array(feature_values) > threshold, numpy.array(labels) == -1))
    false_positive = numpy.array(numpy.logical_and( numpy.array(feature_values) <= threshold, numpy.array(labels) == 1))
    false_negative = numpy.array(numpy.logical_and( numpy.array(feature_values) <= threshold, numpy.array(labels) == -1))
    
    sum_true_positive = sum(true_positive)
    sum_true_negative = sum(true_negative)
    sum_false_positive = sum(false_positive)
    sum_false_negative = sum(false_negative)

    sum_true = sum_true_positive+sum_true_negative
    sum_false = sum_false_positive+sum_false_negative
    total  = len(labels)
    
    gini_true = 0
    gini_false = 0

    if (sum_true ==0):
      gini_true = 0.5
      gini_false = 1-(sum_false_positive/sum_false)**2-(sum_false_negative/sum_false)**2

    elif (sum_false==0):
      gini_false =0.5
      gini_true =  1-(sum_true_positive/sum_true)**2-(sum_true_negative/sum_true)**2
    else:
      gini_true =  1-(sum_true_positive/sum_true)**2-(sum_true_negative/sum_true)**2
      gini_false = 1-(sum_false_positive/sum_false)**2-(sum_false_negative/sum_false)**2

    expectation = (sum_true/total)*gini_true + (sum_false/total)*gini_false
    
    return expectation

def midpoint(x):
  
    return (x[1:] + x[:-1]) / 2

def grid_search_split_midpoint(X, y): 
    
    X_sorted = numpy.sort(X, axis=0)
    thresholds = numpy.apply_along_axis(midpoint, 0, X_sorted)
    grid = numpy.zeros((thresholds.shape[0],thresholds.shape[1]))

    for i in range(thresholds.shape[1]): 
      for j in range (thresholds.shape[0]):
         grid [j,i]= estimate_gini_impurity_expectation( numpy.array (X[:,i]), thresholds[j,i], y)

    m = numpy.argwhere(grid == grid.min())
    best_feature = m[0,1]
    best_threshold = thresholds[m[0,0],m[0,1]]


    return grid,best_feature, best_threshold

def you_rock(N, R, d):
    """
    N: int, number of samples, e.g., 1000. 
    R: int, maximum feature value, e.g., 100. 
    d: int, number of features, e.g., 3. 
    """
    numpy.random.seed() # re-random the seed 
    hits = 0
    for _ in range(N):
        X = numpy.random.randint(1, R, (8,d)) # generate training samples
        y = numpy.array([+1,+1,+1,+1, -1,-1,-1,-1])
        _, feature_id, bts = grid_search_split_midpoint(X, y)
        clf = sklearn.tree.DecisionTreeClassifier(max_depth=1)
        clf = clf.fit(X,y)
        
        if clf.tree_.feature[0] == feature_id and clf.tree_.threshold[0] == bts:
            hits += 1 
    print ("your Decision tree is {:2.2%} consistent with Scikit-learn's result.".format(hits/N))

if __name__ == "__main__":
    import doctest
    doctest.testmod()
    you_rock(1000, 100, 3)